{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "which_set(training,testing,validation).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayhuMXQag_d_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def which_set(filename, validation_percentage, testing_percentage):\n",
        "  \"\"\"Determines which data partition the file should belong to.\n",
        "\n",
        "  We want to keep files in the same training, validation, or testing sets even\n",
        "  if new ones are added over time. This makes it less likely that testing\n",
        "  samples will accidentally be reused in training when long runs are restarted\n",
        "  for example. To keep this stability, a hash of the filename is taken and used\n",
        "  to determine which set it should belong to. This determination only depends on\n",
        "  the name and the set proportions, so it won't change as other files are added.\n",
        "\n",
        "  It's also useful to associate particular files as related (for example words\n",
        "  spoken by the same person), so anything after '_nohash_' in a filename is\n",
        "  ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
        "  'bobby_nohash_1.wav' are always in the same set, for example.\n",
        "\n",
        "  Args:\n",
        "    filename: File path of the data sample.\n",
        "    validation_percentage: How much of the data set to use for validation.\n",
        "    testing_percentage: How much of the data set to use for testing.\n",
        "\n",
        "  Returns:\n",
        "    String, one of 'training', 'validation', or 'testing'.\n",
        "  \"\"\"\n",
        "  base_name = os.path.basename(filename)\n",
        "  # We want to ignore anything after '_nohash_' in the file name when\n",
        "  # deciding which set to put a wav in, so the data set creator has a way of\n",
        "  # grouping wavs that are close variations of each other.\n",
        "  hash_name = re.sub(r'_nohash_.*$', '', base_name)\n",
        "  # This looks a bit magical, but we need to decide whether this file should\n",
        "  # go into the training, testing, or validation sets, and we want to keep\n",
        "  # existing files in the same set even if more files are subsequently\n",
        "  # added.\n",
        "  # To do that, we need a stable way of deciding based on just the file name\n",
        "  # itself, so we do a hash of that and then use that to generate a\n",
        "  # probability value that we use to assign it.\n",
        "  hash_name_hashed = hashlib.sha1(hash_name).hexdigest()\n",
        "  percentage_hash = ((int(hash_name_hashed, 16) %\n",
        "                      (MAX_NUM_WAVS_PER_CLASS + 1)) *\n",
        "                     (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
        "  if percentage_hash < validation_percentage:\n",
        "    result = 'validation'\n",
        "  elif percentage_hash < (testing_percentage + validation_percentage):\n",
        "    result = 'testing'\n",
        "  else:\n",
        "    result = 'training'\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}